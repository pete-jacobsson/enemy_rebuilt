{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6b9914-1ce5-46cd-9625-a49a69f44690",
   "metadata": {},
   "source": [
    "## Physical Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9809fcc4-4f08-4bee-84e6-c8b406d04925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from world_simulator import run_river_skeleton_pipeline, test_noise, generate_fractal_noise\n",
    "from world_simulator import GPUThermalEroder, CoastalTaper\n",
    "\n",
    "from world_simulator import HydrologyAnalyzer, validate_arrow_directions, plot_flow, CalculateFlowMagnitude, plot_river_hierarchy, assign_river_widths, plot_river_physics, save_hydro_network, validate_topology_continuity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from gdgtm import change_raster_res\n",
    "\n",
    "\n",
    "vector_src_dir = \"/home/pete/Documents/wfrp/source_vectors/\"\n",
    "raster_src_dir = \"/home/pete/Documents/wfrp/source_rasters/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265c09c-05a8-4da5-963a-46bff78dd70e",
   "metadata": {},
   "source": [
    "## River and sea setup\n",
    "\n",
    "Here we take a georeferenced, trimmed corase altitude map, we load it, increase resolution, and then we smooth it.\n",
    "\n",
    "We use an erosion approach to overal smoothing and aim for Int16 data type - which gives us some serious mileage in the \"disk saving department\" - 100s of MBs.\n",
    "\n",
    "The exact maths are indicated in the class docstring for the GPUThermalEroder. For now it is relevant to note that we went for a short erosion (100 steps), slow erosion rate (0.05), and a high threshold of 2. What this means is that we preserve most of the high ground on the map, while introducing just a little smoothing around the slopes to remove the blockiness. Not perfect, but the step below will take care of doing perfect :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd92dbe-bde7-4a5c-be77-40d0ae6f29c4",
   "metadata": {},
   "source": [
    "### Vectorizing the river net from QGIS polys\n",
    "\n",
    "The goal here is to take a bunch of QGIS polygons and change them into an actual net of lines for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8d2a9-280e-4b73-86db-a17041ab06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Example configuration\n",
    "#     IN_FILE = os.path.join(vector_src_dir, \"wfrp_empire_rivers_poly.gpkg\")\n",
    "#     OUT_FILE = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "    \n",
    "#     # Config\n",
    "#     GAP_TOLERANCE = 3500     # 20km gap filling\n",
    "#     INTERP_DISTANCE = 250     # 500m vertex resolution\n",
    "#     PRUNE = 3500\n",
    "    \n",
    "#     if os.path.exists(IN_FILE):\n",
    "#         run_river_skeleton_pipeline(IN_FILE, OUT_FILE, GAP_TOLERANCE, INTERP_DISTANCE, PRUNE)\n",
    "#     else:\n",
    "#         print(f\"File not found: {IN_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9e538-37f7-4aa8-9d81-9cbd3b882cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Phase 1: Make the rivers flow and make them have the right size.\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # rivers_path = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "#     sea_path = os.path.join(vector_src_dir, \"wfrp_empire_sea_poly.gpkg\")\n",
    "#     lakes_path = os.path.join(vector_src_dir, \"wfrp_empire_lakes_poly.gpkg\")\n",
    "#     rivers_path = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "    \n",
    "#     rivers = gpd.read_file(rivers_path) # The output from skeletonization\n",
    "#     sea = gpd.read_file(sea_path)       # You need this\n",
    "#     lakes = gpd.read_file(lakes_path)   # You need this (Canonical lakes)\n",
    "\n",
    "#     ### Step 1: Orient the rivers in the correct direction.\n",
    "#     analyzer = HydrologyAnalyzer(rivers, sea, lakes)\n",
    "#     oriented_rivers = analyzer.run()\n",
    "#     validate_arrow_directions(oriented_rivers, analyzer.G)\n",
    "#     # plot_flow(oriented_rivers, sea, lakes)\n",
    "\n",
    "#     ### Step 2: Establish river hierarchy\n",
    "#     # 1. Get the Directed Graph from the Phase 1 Analyzer\n",
    "#     flow_calculator = CalculateFlowMagnitude(analyzer.DiG)\n",
    "#     # 2. Calculate Magnitude\n",
    "#     dag_with_flow = flow_calculator.run()\n",
    "#     # 3. Visualize\n",
    "#     # plot_river_hierarchy(dag_with_flow, sea, lakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd1ff7-e31d-4d6c-9460-30d85ed4b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     OUT_FILE = os.path.join(vector_src_dir, \"wfrp_empire_major_rivers_net.gpkg\")\n",
    "#     ### Step 3: Work out river widths:\n",
    "#     rivers_with_width = assign_river_widths(\n",
    "#         dag_with_flow, \n",
    "#         min_width=20.0,    # Source streams are 20m wide\n",
    "#         max_width=1000.0,   # The Reik is 800m wide at Altdorf - we make it 1000 for our 250m grid.\n",
    "#         scale_factor=100.0  # Multiplier for the log growth\n",
    "#     )\n",
    "    \n",
    "#     # 2. Restore CRS (Important for buffering!)\n",
    "#     rivers_with_width.set_crs(rivers.crs, inplace=True)\n",
    "    \n",
    "#     # 3. Visualize\n",
    "#     # plot_river_physics(rivers_with_width, sea, lakes)\n",
    "#     save_hydro_network(rivers_with_width, OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31778896-062f-4025-830d-b5c8e90a34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOPOLOGY CONTINUITY CHECK ---\n",
      "Checked 100 junctions.\n",
      "SUCCESS: Water flows continuously from line to line.\n"
     ]
    }
   ],
   "source": [
    "# validate_topology_continuity(rivers_with_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160d84e-93f7-47b0-8da3-6ba0a1d839de",
   "metadata": {},
   "source": [
    "### Sea set-up\n",
    "\n",
    "Here we prep the sea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10092cd6-21b7-4ac6-853f-0a187c1fca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/miniconda/envs/gdgtm_dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074409.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# from world_simulator.terrain_engine import CoordinateEngine\n",
    "# Added necessary utility functions for Step 2\n",
    "from world_simulator.misc_utils import (\n",
    "    vector_to_mask, \n",
    "    generate_fractal_mask, \n",
    "    measure_fractal_dimension,\n",
    "    repair_mask_artifacts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e8aeec-3ea3-4fb6-84a4-315f1a2a913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  STEP 1: LOAD CONTEXT DATA\n",
    "# =============================================================================\n",
    "\n",
    "vector_src = \"/home/pete/Documents/wfrp/source_vectors\"\n",
    "raster_src = \"/home/pete/Documents/wfrp/source_rasters\"\n",
    "\n",
    "# A. The Base DEM (Canvas & Starting Heights)\n",
    "base_dem_path = os.path.join(raster_src, \"wfrp_empire_smoothed_topo.tif\") # From your previous step\n",
    "with rasterio.open(base_dem_path) as src:\n",
    "    base_profile = src.profile\n",
    "    base_shape = (src.height, src.width)\n",
    "    base_elevation = src.read(1) # Start with existing terrain\n",
    "\n",
    "# B. Vectors\n",
    "rivers_gdf = gpd.read_file(os.path.join(vector_src, \"wfrp_empire_major_rivers_net.gpkg\"))\n",
    "lakes_gdf = gpd.read_file(\n",
    "    os.path.join(vector_src, \"wfrp_empire_lakes_poly.gpkg\"),\n",
    "    layer=\"wfrp_empire_lakes\")\n",
    "sea_gdf = gpd.read_file(os.path.join(vector_src, \"wfrp_empire_sea_poly.gpkg\")) # Explicit Sea Load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b3e802-1a78-4133-8979-3a7c52b830ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Coastline Physics...\n",
      "INFO: Rasterizing 11 vector features into mask...\n",
      "  > Detected Fractal Dimension: 1.224\n",
      "Repairing map boundary artifacts...\n",
      "INFO: Repairing artifacts in 2 zones...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  STEP 2: PRE-PROCESS COAST (Measure & Mimic)\n",
    "# =============================================================================\n",
    "# --- A. COASTAL ANALYSIS ---\n",
    "print(\"Analyzing Coastline Physics...\")\n",
    "\n",
    "# 1. Rasterize (Get the shape)\n",
    "raw_sea_mask = vector_to_mask(sea_gdf, base_profile)\n",
    "\n",
    "# Define the artifact zones (Map edges/NoData boundaries)\n",
    "# Format: (West_Col, North_Row, East_Col, South_Row)\n",
    "artifact_boxes = [\n",
    "    (0, 1050, 100, 1300),   # Box 1: West edge artifact\n",
    "    (3500, 0, 7100, 900)    # Box 2: Northern edge artifact\n",
    "]\n",
    "\n",
    "# 2. Measure the \"Native\" Fractal Dimension\n",
    "# We measure the complexity at coarse scales (e.g., 2km to 64km).\n",
    "# This tells us if the coast is \"Scottish\" (High D) or \"Floridian\" (Low D).\n",
    "# We stop at min_scale=16px (~2km) to avoid reading the square pixel artifacts.\n",
    "measured_d = measure_fractal_dimension(\n",
    "    mask=raw_sea_mask,\n",
    "    min_scale=16,   # Ignore details smaller than ~2km\n",
    "    max_scale=512,  # Measure up to ~64km bays\n",
    "    exclusion_boxes=artifact_boxes  # <--- Plugged in here\n",
    ")\n",
    "\n",
    "# print(f\"Measured Fractal Dimension: {measured_d}\")\n",
    "\n",
    "# Safety Clamp: Real coastlines rarely exceed 1.5 or drop below 1.1\n",
    "measured_d = np.clip(measured_d, 1.1, 1.45)\n",
    "print(f\"  > Detected Fractal Dimension: {measured_d:.3f}\")\n",
    "\n",
    "# 3. Synthesize Detail\n",
    "# We use the measured D to generate the sub-pixel details.\n",
    "fractal_sea_mask = generate_fractal_mask(\n",
    "    mask=raw_sea_mask,\n",
    "    fractal_dimension=measured_d,  # <--- The Measurement informs the Synthesis\n",
    "    scale=20.0,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# 4. Repair Boundaries\n",
    "# We surgically restore the straight edges in the artifact boxes\n",
    "# to prevent the fractal noise from 'chewing' up the map border.\n",
    "print(\"Repairing map boundary artifacts...\")\n",
    "fractal_sea_mask = repair_mask_artifacts(\n",
    "    fractal_mask=fractal_sea_mask,\n",
    "    reference_mask=raw_sea_mask,      # The clean original\n",
    "    boxes=artifact_boxes,             # <--- Plugged in here again\n",
    "    base_dem=base_elevation,          # Check for valid data\n",
    "    nodata_value=base_profile.get('nodata', -32768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce9d759-73aa-4dca-a35c-aa8efd473464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting debug mask to /home/pete/Documents/wfrp/source_rasters/wfrp_coast_mask_test.tif...\n",
      "Debug export complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  DEBUG EXPORT: FRACTAL SEA MASK\n",
    "# =============================================================================\n",
    "output_mask_path = os.path.join(raster_src, \"wfrp_coast_mask_test.tif\")\n",
    "print(f\"Exporting debug mask to {output_mask_path}...\")\n",
    "\n",
    "# Prepare Profile\n",
    "mask_profile = base_profile.copy()\n",
    "mask_profile.update({\n",
    "    'dtype': 'uint8',\n",
    "    'count': 1,\n",
    "    'compress': 'lzw',\n",
    "    'nodata': 0 \n",
    "})\n",
    "\n",
    "with rasterio.open(output_mask_path, 'w', **mask_profile) as dst:\n",
    "    # Cast Boolean (True/False) to Uint8 (1/0)\n",
    "    # OPTIONAL: Multiply by 255 so it appears as Black/White in QGIS immediately\n",
    "    # without needing to stretch the histogram manually.\n",
    "    debug_data = fractal_sea_mask.astype('uint8') * 255\n",
    "    \n",
    "    dst.write(debug_data, 1)\n",
    "\n",
    "print(\"Debug export complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff3a76-882d-4c4c-b19c-0774d22101c2",
   "metadata": {},
   "source": [
    "## Topography: \n",
    "\n",
    "The plan is outlined here: https://github.com/pete-jacobsson/enemy_rebuilt/wiki/Topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e73ac-3f1d-43c4-b8f6-9bccbac35326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  PHASE 1: IMPORTS & RAW DATA INGESTION\n",
    "# =============================================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Configuration: File Paths\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_DIR = \"/home/pete/Documents/wfrp\"\n",
    "\n",
    "# File definitions matching your manifest\n",
    "files = {\n",
    "    \"gcm\":    os.path.join(INPUT_DIR, \"geology_mask.gpkg\"),  # 5-Zone Vector Mask\n",
    "    \"dem\":    os.path.join(INPUT_DIR, \"canonical_dem.tif\"),  # Coarse Heightmap\n",
    "    \"rivers\": os.path.join(INPUT_DIR, \"rivers.gpkg\"),        # River Vectors\n",
    "    \"lakes\":  os.path.join(INPUT_DIR, \"lakes.gpkg\"),         # Lake Polygons\n",
    "    \"sea\":    os.path.join(INPUT_DIR, \"sea.gpkg\")            # Sea Polygons\n",
    "}\n",
    "\n",
    "# 2. Load Raster Data (The Base DEM)\n",
    "# -----------------------------------------------------------------------------\n",
    "# We keep the source open or read immediately into memory. \n",
    "# Here we read the data and profile to establish the baseline grid/CRS.\n",
    "try:\n",
    "    with rasterio.open(files['dem']) as src:\n",
    "        base_dem_data = src.read(1)  # Read the first band\n",
    "        base_profile = src.profile   # Metadata (CRS, Transform, Width, Height)\n",
    "        base_bounds = src.bounds     # Physical extent\n",
    "    \n",
    "    print(f\"SUCCESS: Loaded Base DEM.\")\n",
    "    print(f\"  - Shape: {base_dem_data.shape}\")\n",
    "    print(f\"  - CRS: {base_profile['crs']}\")\n",
    "    print(f\"  - Bounds: {base_bounds}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load DEM. {e}\")\n",
    "\n",
    "# 3. Load Vector Data (Geological Mask, Hydro, Coastline)\n",
    "# -----------------------------------------------------------------------------\n",
    "# We load these as GeoDataFrames. No rasterization yet.\n",
    "try:\n",
    "    # A. Geological Control Map (Zone 1-5)\n",
    "    gdf_gcm = gpd.read_file(files['gcm'])\n",
    "    print(f\"SUCCESS: Loaded GCM ({len(gdf_gcm)} polygons).\")\n",
    "\n",
    "    # B. Hydrology\n",
    "    gdf_rivers = gpd.read_file(files['rivers'])\n",
    "    print(f\"SUCCESS: Loaded Rivers ({len(gdf_rivers)} segments).\")\n",
    "\n",
    "    gdf_lakes = gpd.read_file(files['lakes'])\n",
    "    print(f\"SUCCESS: Loaded Lakes ({len(gdf_lakes)} polygons).\")\n",
    "\n",
    "    # C. Coastline / Sea\n",
    "    gdf_sea = gpd.read_file(files['sea'])\n",
    "    print(f\"SUCCESS: Loaded Sea Mask ({len(gdf_sea)} polygons).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load vector data. {e}\")\n",
    "\n",
    "# 4. Quick CRS Consistency Check\n",
    "# -----------------------------------------------------------------------------\n",
    "# All vectors must match the DEM's CRS.\n",
    "vectors = {'GCM': gdf_gcm, 'Rivers': gdf_rivers, 'Lakes': gdf_lakes, 'Sea': gdf_sea}\n",
    "dem_crs = base_profile['crs']\n",
    "\n",
    "print(\"\\n--- CRS Consistency Check ---\")\n",
    "for name, gdf in vectors.items():\n",
    "    if gdf.crs != dem_crs:\n",
    "        print(f\"WARNING: {name} CRS ({gdf.crs}) does not match DEM ({dem_crs}). Reprojection required later.\")\n",
    "    else:\n",
    "        print(f\"OK: {name} matches DEM CRS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7308b9-dcdc-4819-a51f-2a9665a4ffe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfcadf-1308-49aa-9038-213333d4cefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55df53c-c94b-4b96-863f-8608eec0444b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5884fe-f8f1-4171-af91-3be115d171ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0b06b-3c73-49db-ae68-f88ce19d2615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c1f46a-f25a-4e85-847d-f2b189edc1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Warp Debug Grid...\n",
      "Check /home/pete/Documents/wfrp/debug_folding.tif in QGIS.\n",
      "If the grid lines are perfectly straight, the warp is BROKEN.\n",
      "If the grid lines curve near rivers, the warp WORKS.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  DEBUG: VISUALIZE THE WARP FIELD (Graph Paper Mode)\n",
    "# =============================================================================\n",
    "print(\"Generating Warp Debug Grid...\")\n",
    "\n",
    "# 1. Access the internal coordinate fabric\n",
    "# These should have been modified by the RiverWarpLayer\n",
    "warped_x = engine.coords_x\n",
    "warped_y = engine.coords_y\n",
    "\n",
    "# 2. Generate a Grid Pattern\n",
    "# We create white lines every 500 pixels\n",
    "spacing = 500      # Size of the grid squares (pixels)\n",
    "thickness = 40     # Thickness of the lines (pixels)\n",
    "\n",
    "# Logic: If the coordinate modulo spacing is less than thickness, draw a line.\n",
    "# This draws lines based on WHERE the pixel \"thinks\" it is in the warped space.\n",
    "vert_lines = (warped_x % spacing) < thickness\n",
    "horiz_lines = (warped_y % spacing) < thickness\n",
    "\n",
    "# Combine Vertical + Horizontal\n",
    "grid_pattern = np.logical_or(vert_lines, horiz_lines)\n",
    "\n",
    "# 3. Export\n",
    "debug_path = \"/home/pete/Documents/wfrp/debug_folding.tif\"\n",
    "with rasterio.open(debug_path, 'w', **base_profile) as dst:\n",
    "    # Convert Boolean (True/False) to Uint8 (255/0) for visibility\n",
    "    debug_img = grid_pattern.astype(np.uint8) * 255\n",
    "    dst.write(debug_img, 1)\n",
    "\n",
    "print(f\"Check {debug_path} in QGIS.\")\n",
    "print(\"If the grid lines are perfectly straight, the warp is BROKEN.\")\n",
    "print(\"If the grid lines curve near rivers, the warp WORKS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c111281-50d9-4b3d-bb69-7bcbd07be842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023bbe6-acd8-4d4e-aab8-ade78b38e8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fc939-1548-4715-8f67-90f5e2984455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ff594-b561-44b2-a216-274d9bd5045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4259b-d4e2-4838-b192-b3a23d02b4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6547797-98fe-4770-ac90-67b4a8839dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0966ed36-1355-432c-b1ca-a5d592cc8481",
   "metadata": {},
   "source": [
    "What this will not do is getting a good coastal taper. For this we use the CoastalTaper class.\n",
    "For this we set ourselves at 250 pixels from the shore (which means base DEM elevation is reached some 27.25km from the Sea of Claws). The power is the default of 2 - this means a wide coastal plain and a steep rise that still preserves the hills in the north of Nordland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61542b5-7177-423a-9ba5-e5e5612a46f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cf7a3-017b-424c-af16-61b96978aca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c664d7a-eed1-44fa-8192-e307fc3c8b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bf085-4340-4cd8-b92a-08ea9daaf57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78069c-e899-49f5-a627-04b5dc32cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036b8bd-5402-4cfc-9099-8edf69491db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d1527-06b3-4064-afc9-fa07fac1c126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c3747-a930-48e3-8dac-ed62817ff5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56363c4-686d-42ed-9ac2-fd15bb57380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5e1eb-b2a6-426b-a722-ba01950104aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a080d-5d6e-4ec5-b20a-ade4e27c8330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d9a5f-96d5-4f27-acad-a34e4d69849d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(gdgtm_dev)",
   "language": "python",
   "name": "gdgtm_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
