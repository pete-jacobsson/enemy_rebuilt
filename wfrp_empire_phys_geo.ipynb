{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6b9914-1ce5-46cd-9625-a49a69f44690",
   "metadata": {},
   "source": [
    "## Physical Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9809fcc4-4f08-4bee-84e6-c8b406d04925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from world_simulator import run_river_skeleton_pipeline, test_noise, generate_fractal_noise\n",
    "from world_simulator import GPUThermalEroder, CoastalTaper\n",
    "\n",
    "from world_simulator import HydrologyAnalyzer, validate_arrow_directions, plot_flow, CalculateFlowMagnitude, plot_river_hierarchy, assign_river_widths, plot_river_physics, save_hydro_network, validate_topology_continuity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from gdgtm import change_raster_res\n",
    "\n",
    "\n",
    "vector_src_dir = \"/home/pete/Documents/wfrp/source_vectors/\"\n",
    "raster_src_dir = \"/home/pete/Documents/wfrp/source_rasters/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265c09c-05a8-4da5-963a-46bff78dd70e",
   "metadata": {},
   "source": [
    "## River and sea setup\n",
    "\n",
    "Here we take a georeferenced, trimmed corase altitude map, we load it, increase resolution, and then we smooth it.\n",
    "\n",
    "We use an erosion approach to overal smoothing and aim for Int16 data type - which gives us some serious mileage in the \"disk saving department\" - 100s of MBs.\n",
    "\n",
    "The exact maths are indicated in the class docstring for the GPUThermalEroder. For now it is relevant to note that we went for a short erosion (100 steps), slow erosion rate (0.05), and a high threshold of 2. What this means is that we preserve most of the high ground on the map, while introducing just a little smoothing around the slopes to remove the blockiness. Not perfect, but the step below will take care of doing perfect :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd92dbe-bde7-4a5c-be77-40d0ae6f29c4",
   "metadata": {},
   "source": [
    "### Vectorizing the river net from QGIS polys\n",
    "\n",
    "The goal here is to take a bunch of QGIS polygons and change them into an actual net of lines for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8d2a9-280e-4b73-86db-a17041ab06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Example configuration\n",
    "#     IN_FILE = os.path.join(vector_src_dir, \"wfrp_empire_rivers_poly.gpkg\")\n",
    "#     OUT_FILE = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "    \n",
    "#     # Config\n",
    "#     GAP_TOLERANCE = 3500     # 20km gap filling\n",
    "#     INTERP_DISTANCE = 250     # 500m vertex resolution\n",
    "#     PRUNE = 3500\n",
    "    \n",
    "#     if os.path.exists(IN_FILE):\n",
    "#         run_river_skeleton_pipeline(IN_FILE, OUT_FILE, GAP_TOLERANCE, INTERP_DISTANCE, PRUNE)\n",
    "#     else:\n",
    "#         print(f\"File not found: {IN_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9e538-37f7-4aa8-9d81-9cbd3b882cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Phase 1: Make the rivers flow and make them have the right size.\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # rivers_path = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "#     sea_path = os.path.join(vector_src_dir, \"wfrp_empire_sea_poly.gpkg\")\n",
    "#     lakes_path = os.path.join(vector_src_dir, \"wfrp_empire_lakes_poly.gpkg\")\n",
    "#     rivers_path = os.path.join(vector_src_dir, \"wfrp_empire_rivers_line.gpkg\")\n",
    "    \n",
    "#     rivers = gpd.read_file(rivers_path) # The output from skeletonization\n",
    "#     sea = gpd.read_file(sea_path)       # You need this\n",
    "#     lakes = gpd.read_file(lakes_path)   # You need this (Canonical lakes)\n",
    "\n",
    "#     ### Step 1: Orient the rivers in the correct direction.\n",
    "#     analyzer = HydrologyAnalyzer(rivers, sea, lakes)\n",
    "#     oriented_rivers = analyzer.run()\n",
    "#     validate_arrow_directions(oriented_rivers, analyzer.G)\n",
    "#     # plot_flow(oriented_rivers, sea, lakes)\n",
    "\n",
    "#     ### Step 2: Establish river hierarchy\n",
    "#     # 1. Get the Directed Graph from the Phase 1 Analyzer\n",
    "#     flow_calculator = CalculateFlowMagnitude(analyzer.DiG)\n",
    "#     # 2. Calculate Magnitude\n",
    "#     dag_with_flow = flow_calculator.run()\n",
    "#     # 3. Visualize\n",
    "#     # plot_river_hierarchy(dag_with_flow, sea, lakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd1ff7-e31d-4d6c-9460-30d85ed4b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     OUT_FILE = os.path.join(vector_src_dir, \"wfrp_empire_major_rivers_net.gpkg\")\n",
    "#     ### Step 3: Work out river widths:\n",
    "#     rivers_with_width = assign_river_widths(\n",
    "#         dag_with_flow, \n",
    "#         min_width=20.0,    # Source streams are 20m wide\n",
    "#         max_width=1000.0,   # The Reik is 800m wide at Altdorf - we make it 1000 for our 250m grid.\n",
    "#         scale_factor=100.0  # Multiplier for the log growth\n",
    "#     )\n",
    "    \n",
    "#     # 2. Restore CRS (Important for buffering!)\n",
    "#     rivers_with_width.set_crs(rivers.crs, inplace=True)\n",
    "    \n",
    "#     # 3. Visualize\n",
    "#     # plot_river_physics(rivers_with_width, sea, lakes)\n",
    "#     save_hydro_network(rivers_with_width, OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31778896-062f-4025-830d-b5c8e90a34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOPOLOGY CONTINUITY CHECK ---\n",
      "Checked 100 junctions.\n",
      "SUCCESS: Water flows continuously from line to line.\n"
     ]
    }
   ],
   "source": [
    "# validate_topology_continuity(rivers_with_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160d84e-93f7-47b0-8da3-6ba0a1d839de",
   "metadata": {},
   "source": [
    "### Sea set-up\n",
    "\n",
    "Here we prep the sea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10092cd6-21b7-4ac6-853f-0a187c1fca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/miniconda/envs/gdgtm_dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074409.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251224_074410.log\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# from world_simulator.terrain_engine import CoordinateEngine\n",
    "# Added necessary utility functions for Step 2\n",
    "from world_simulator.misc_utils import (\n",
    "    vector_to_mask, \n",
    "    generate_fractal_mask, \n",
    "    measure_fractal_dimension,\n",
    "    repair_mask_artifacts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e8aeec-3ea3-4fb6-84a4-315f1a2a913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  STEP 1: LOAD CONTEXT DATA\n",
    "# =============================================================================\n",
    "\n",
    "vector_src = \"/home/pete/Documents/wfrp/source_vectors\"\n",
    "raster_src = \"/home/pete/Documents/wfrp/source_rasters\"\n",
    "\n",
    "# A. The Base DEM (Canvas & Starting Heights)\n",
    "base_dem_path = os.path.join(raster_src, \"wfrp_empire_smoothed_topo.tif\") # From your previous step\n",
    "with rasterio.open(base_dem_path) as src:\n",
    "    base_profile = src.profile\n",
    "    base_shape = (src.height, src.width)\n",
    "    base_elevation = src.read(1) # Start with existing terrain\n",
    "\n",
    "# B. Vectors\n",
    "rivers_gdf = gpd.read_file(os.path.join(vector_src, \"wfrp_empire_major_rivers_net.gpkg\"))\n",
    "lakes_gdf = gpd.read_file(\n",
    "    os.path.join(vector_src, \"wfrp_empire_lakes_poly.gpkg\"),\n",
    "    layer=\"wfrp_empire_lakes\")\n",
    "sea_gdf = gpd.read_file(os.path.join(vector_src, \"wfrp_empire_sea_poly.gpkg\")) # Explicit Sea Load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b3e802-1a78-4133-8979-3a7c52b830ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Coastline Physics...\n",
      "INFO: Rasterizing 11 vector features into mask...\n",
      "  > Detected Fractal Dimension: 1.224\n",
      "Repairing map boundary artifacts...\n",
      "INFO: Repairing artifacts in 2 zones...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  STEP 2: PRE-PROCESS COAST (Measure & Mimic)\n",
    "# =============================================================================\n",
    "# --- A. COASTAL ANALYSIS ---\n",
    "print(\"Analyzing Coastline Physics...\")\n",
    "\n",
    "# 1. Rasterize (Get the shape)\n",
    "raw_sea_mask = vector_to_mask(sea_gdf, base_profile)\n",
    "\n",
    "# Define the artifact zones (Map edges/NoData boundaries)\n",
    "# Format: (West_Col, North_Row, East_Col, South_Row)\n",
    "artifact_boxes = [\n",
    "    (0, 1050, 100, 1300),   # Box 1: West edge artifact\n",
    "    (3500, 0, 7100, 900)    # Box 2: Northern edge artifact\n",
    "]\n",
    "\n",
    "# 2. Measure the \"Native\" Fractal Dimension\n",
    "# We measure the complexity at coarse scales (e.g., 2km to 64km).\n",
    "# This tells us if the coast is \"Scottish\" (High D) or \"Floridian\" (Low D).\n",
    "# We stop at min_scale=16px (~2km) to avoid reading the square pixel artifacts.\n",
    "measured_d = measure_fractal_dimension(\n",
    "    mask=raw_sea_mask,\n",
    "    min_scale=16,   # Ignore details smaller than ~2km\n",
    "    max_scale=512,  # Measure up to ~64km bays\n",
    "    exclusion_boxes=artifact_boxes  # <--- Plugged in here\n",
    ")\n",
    "\n",
    "# print(f\"Measured Fractal Dimension: {measured_d}\")\n",
    "\n",
    "# Safety Clamp: Real coastlines rarely exceed 1.5 or drop below 1.1\n",
    "measured_d = np.clip(measured_d, 1.1, 1.45)\n",
    "print(f\"  > Detected Fractal Dimension: {measured_d:.3f}\")\n",
    "\n",
    "# 3. Synthesize Detail\n",
    "# We use the measured D to generate the sub-pixel details.\n",
    "fractal_sea_mask = generate_fractal_mask(\n",
    "    mask=raw_sea_mask,\n",
    "    fractal_dimension=measured_d,  # <--- The Measurement informs the Synthesis\n",
    "    scale=20.0,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# 4. Repair Boundaries\n",
    "# We surgically restore the straight edges in the artifact boxes\n",
    "# to prevent the fractal noise from 'chewing' up the map border.\n",
    "print(\"Repairing map boundary artifacts...\")\n",
    "fractal_sea_mask = repair_mask_artifacts(\n",
    "    fractal_mask=fractal_sea_mask,\n",
    "    reference_mask=raw_sea_mask,      # The clean original\n",
    "    boxes=artifact_boxes,             # <--- Plugged in here again\n",
    "    base_dem=base_elevation,          # Check for valid data\n",
    "    nodata_value=base_profile.get('nodata', -32768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce9d759-73aa-4dca-a35c-aa8efd473464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting debug mask to /home/pete/Documents/wfrp/source_rasters/wfrp_coast_mask_test.tif...\n",
      "Debug export complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  DEBUG EXPORT: FRACTAL SEA MASK\n",
    "# =============================================================================\n",
    "output_mask_path = os.path.join(raster_src, \"wfrp_coast_mask_test.tif\")\n",
    "print(f\"Exporting debug mask to {output_mask_path}...\")\n",
    "\n",
    "# Prepare Profile\n",
    "mask_profile = base_profile.copy()\n",
    "mask_profile.update({\n",
    "    'dtype': 'uint8',\n",
    "    'count': 1,\n",
    "    'compress': 'lzw',\n",
    "    'nodata': 0 \n",
    "})\n",
    "\n",
    "with rasterio.open(output_mask_path, 'w', **mask_profile) as dst:\n",
    "    # Cast Boolean (True/False) to Uint8 (1/0)\n",
    "    # OPTIONAL: Multiply by 255 so it appears as Black/White in QGIS immediately\n",
    "    # without needing to stretch the histogram manually.\n",
    "    debug_data = fractal_sea_mask.astype('uint8') * 255\n",
    "    \n",
    "    dst.write(debug_data, 1)\n",
    "\n",
    "print(\"Debug export complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff3a76-882d-4c4c-b19c-0774d22101c2",
   "metadata": {},
   "source": [
    "## Topography: \n",
    "\n",
    "The plan is outlined here: https://github.com/pete-jacobsson/enemy_rebuilt/wiki/Topography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdeab5-f1d2-495e-920e-a089bbe1745e",
   "metadata": {},
   "source": [
    "### PHASE 1: IMPORTS & RAW DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4cb78b-7315-4004-ada2-006055915ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/miniconda/envs/gdgtm_dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251225_164957.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251225_164958.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251225_164959.log\n",
      "INFO: Logging initialized. Writing to: logs/wfrp_phys_geo_20251225_164959.log\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "from world_simulator import (\n",
    "    rasterize_vector_to_disk,\n",
    "    rasterize_variable_width_rivers,\n",
    "    rasterize_uint8_to_disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8768358-5392-4dbb-928b-45cfcbce7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Loaded Base DEM.\n",
      "ERROR: Could not load DEM. name 'base_dem_data' is not defined\n",
      "SUCCESS: Loaded GCM (15 polygons).\n",
      "SUCCESS: Loaded Rivers (112264 segments).\n",
      "SUCCESS: Loaded Lakes (80 polygons).\n",
      "SUCCESS: Loaded Sea Mask (493 polygons).\n",
      "\n",
      "--- CRS Consistency Check ---\n",
      "OK: gcm matches DEM CRS.\n",
      "OK: rivers matches DEM CRS.\n",
      "OK: lakes matches DEM CRS.\n",
      "OK: sea matches DEM CRS.\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration: File Paths\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_DIR = \"/home/pete/Documents/wfrp\"\n",
    "\n",
    "# File definitions matching your manifest\n",
    "files = {\n",
    "    \"gcm\":    os.path.join(INPUT_DIR, \"source_vectors/wfrp_empire_geo_control.gpkg\"),  # 5-Zone Vector Mask\n",
    "    \"dem\":    os.path.join(INPUT_DIR, \"source_rasters/wfrp_empire_topo_high_res.tif\"),  # Coarse Heightmap\n",
    "    \"rivers\": os.path.join(INPUT_DIR, \"source_vectors/wfrp_empire_major_rivers_net.gpkg\"),        # River Vectors\n",
    "    \"lakes\":  os.path.join(INPUT_DIR, \"source_vectors/wfrp_empire_lakes_high_res_poly.gpkg\"),         # Lake Polygons\n",
    "    \"sea\":    os.path.join(INPUT_DIR, \"source_vectors/wfrp_empire_sea_high_res_poly.gpkg\")            # Sea Polygons\n",
    "}\n",
    "\n",
    "# 2. Load Raster Data (The Base DEM)\n",
    "# -----------------------------------------------------------------------------\n",
    "# We keep the source open or read immediately into memory. \n",
    "# Here we read the data and profile to establish the baseline grid/CRS.\n",
    "try:\n",
    "    with rasterio.open(files['dem']) as src:\n",
    "        base_profile = src.profile   # Metadata (CRS, Transform, Width, Height)\n",
    "        base_bounds = src.bounds     # Physical extent\n",
    "    \n",
    "    print(f\"SUCCESS: Loaded Base DEM.\")\n",
    "    print(f\"  - Shape: {base_dem_data.shape}\")\n",
    "    print(f\"  - CRS: {base_profile['crs']}\")\n",
    "    print(f\"  - Bounds: {base_bounds}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load DEM. {e}\")\n",
    "\n",
    "# 3. Load Vector Data (Geological Mask, Hydro, Coastline)\n",
    "# -----------------------------------------------------------------------------\n",
    "# We load these as GeoDataFrames. No rasterization yet.\n",
    "try:\n",
    "    # A. Geological Control Map (Zone 1-5)\n",
    "    gdf_gcm = gpd.read_file(files['gcm'])\n",
    "    print(f\"SUCCESS: Loaded GCM ({len(gdf_gcm)} polygons).\")\n",
    "\n",
    "    # B. Hydrology\n",
    "    gdf_rivers = gpd.read_file(files['rivers'])\n",
    "    print(f\"SUCCESS: Loaded Rivers ({len(gdf_rivers)} segments).\")\n",
    "\n",
    "    gdf_lakes = gpd.read_file(files['lakes'])\n",
    "    print(f\"SUCCESS: Loaded Lakes ({len(gdf_lakes)} polygons).\")\n",
    "\n",
    "    # C. Coastline / Sea\n",
    "    gdf_sea = gpd.read_file(files['sea'])\n",
    "    print(f\"SUCCESS: Loaded Sea Mask ({len(gdf_sea)} polygons).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load vector data. {e}\")\n",
    "\n",
    "# 4. Quick CRS Consistency Check\n",
    "# -----------------------------------------------------------------------------\n",
    "# All vectors must match the DEM's CRS.\n",
    "vectors = {'gcm': gdf_gcm, 'rivers': gdf_rivers, 'lakes': gdf_lakes, 'sea': gdf_sea}\n",
    "dem_crs = base_profile['crs']\n",
    "\n",
    "print(\"\\n--- CRS Consistency Check ---\")\n",
    "for name, gdf in vectors.items():\n",
    "    if gdf.crs != dem_crs:\n",
    "        print(f\"WARNING: {name} CRS ({gdf.crs}) does not match DEM ({dem_crs}). Reprojection required later.\")\n",
    "    else:\n",
    "        print(f\"OK: {name} matches DEM CRS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7308b9-dcdc-4819-a51f-2a9665a4ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Rasterization Sequence...\n",
      "Rasterizing to mask_sea.tif...\n",
      "Saved: /home/pete/Documents/wfrp/processed_masks/mask_sea.tif\n",
      "Rasterizing to mask_lakes.tif...\n",
      "Saved: /home/pete/Documents/wfrp/processed_masks/mask_lakes.tif\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  PHASE 1.1: PREP SIMPLE MASKS AND SAVE TO DISK\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_MASK_DIR = os.path.join(INPUT_DIR, \"processed_masks\")\n",
    "os.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\n",
    "\n",
    "# Define processing targets\n",
    "# Format: (Input Vector Key, Output Filename, All Touched?)\n",
    "# Note: 'All Touched=True' is usually better for Lakes/Sea to ensure \n",
    "# thin coastal features don't disappear.\n",
    "targets = [\n",
    "    (\"sea\", \"mask_sea.tif\", True),\n",
    "    (\"lakes\", \"mask_lakes.tif\", True)\n",
    "]\n",
    "\n",
    "print(\"Starting Rasterization Sequence...\")\n",
    "\n",
    "for key, filename, touch_setting in targets:\n",
    "    output_path = os.path.join(OUTPUT_MASK_DIR, filename)\n",
    "    \n",
    "    # Check if we already loaded it in previous cells, otherwise use path\n",
    "    source = vectors[key] if 'vectors' in locals() and vectors.get(key) is not None else files[key]\n",
    "    \n",
    "    # Execute Function\n",
    "    rasterize_vector_to_disk(\n",
    "        vector_source=source,\n",
    "        template_raster_path=files['dem'],\n",
    "        output_path=output_path,\n",
    "        burn_value=1,\n",
    "        all_touched=touch_setting\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55df53c-c94b-4b96-863f-8608eec0444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting River Rasterization...\n",
      "Buffering river segments by width...\n",
      "Rasterizing variable widths to mask_rivers_variable.tif...\n",
      "Saved: /home/pete/Documents/wfrp/processed_masks/mask_rivers_variable.tif\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  PHASE 1.2: RASTERIZE VARIABLE WIDTH RIVERS\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_MASK_DIR = os.path.join(INPUT_DIR, \"processed_masks\")\n",
    "RIVER_OUTPUT_FILE = \"mask_rivers_variable.tif\"\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_MASK_DIR, RIVER_OUTPUT_FILE)\n",
    "\n",
    "print(\"Starting River Rasterization...\")\n",
    "\n",
    "# Check if 'vectors' dict exists from previous cells, otherwise load from file\n",
    "source = vectors['rivers'] if 'vectors' in locals() and vectors.get('rivers') is not None else files['rivers']\n",
    "\n",
    "# Execute the variable width rasterization\n",
    "# We use the 'width' column identified in your printout\n",
    "rasterize_variable_width_rivers(\n",
    "    vector_source=source,\n",
    "    template_raster_path=files['dem'],\n",
    "    output_path=OUTPUT_PATH,\n",
    "    width_col='width'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0897d4-8245-461d-bb22-e2a5eff2bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GCM Rasterization...\n",
      "Rasterizing Geological Zones (Col: DN) to mask_geology.tif...\n",
      "Saved: /home/pete/Documents/wfrp/processed_masks/mask_geology.tif\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  PHASE 1.3: RASTERIZE GEOLOGICAL CONTROL MAP (GCM)\n",
    "# =============================================================================\n",
    "OUTPUT_MASK_DIR = os.path.join(INPUT_DIR, \"processed_masks\")\n",
    "GCM_OUTPUT_FILE = \"mask_geology.tif\"\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_MASK_DIR, GCM_OUTPUT_FILE)\n",
    "\n",
    "print(\"Starting GCM Rasterization...\")\n",
    "\n",
    "# Source Retrieval\n",
    "source = vectors['gcm'] if 'vectors' in locals() and vectors.get('gcm') is not None else files['gcm']\n",
    "\n",
    "# Execute Rasterization\n",
    "# Using 'DN' as identified in your printout\n",
    "rasterize_uint8_to_disk(\n",
    "    vector_source=source,\n",
    "    template_raster_path=files['dem'],\n",
    "    output_path=OUTPUT_PATH,\n",
    "    value_col='DN'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5e02dc-cdd9-424f-94c8-ee52dabff9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finalizing Phase 1 Memory Cleanup...\n",
      "Phase 1 Complete. All vectors rasterized to 'processed_masks/' and memory cleared.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  PHASE 1 CLEANUP\n",
    "# =============================================================================\n",
    "print(\"\\nFinalizing Phase 1 Memory Cleanup...\")\n",
    "\n",
    "if 'vectors' in locals():\n",
    "    del vectors\n",
    "\n",
    "if 'base_profile' in locals():\n",
    "    del base_profile\n",
    "\n",
    "if 'base_bounds' in locals():\n",
    "    del base_bounds\n",
    "\n",
    "\n",
    "# Force GC\n",
    "gc.collect()\n",
    "\n",
    "print(\"Phase 1 Complete. All vectors rasterized to 'processed_masks/' and memory cleared.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464fa52-921c-4169-93e8-73ea90ebda05",
   "metadata": {},
   "source": [
    "### PHASE 2: Macro-Sculpting (The Foundation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f31912-276f-40fd-a8da-343f6adee027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e73168-8815-47ce-acb5-c2ef1dc3d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dem and gcm loaded!\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration: File Paths\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_DIR = \"/home/pete/Documents/wfrp\"\n",
    "\n",
    "# File definitions matching your manifest\n",
    "files = {\n",
    "    \"gcm\":    os.path.join(INPUT_DIR, \"processed_masks/mask_geology.tif\"),  # 5-Zone Vector Mask\n",
    "    \"dem\":    os.path.join(INPUT_DIR, \"source_rasters/wfrp_empire_topo_high_res.tif\"),  # Coarse Heightmap\n",
    "}\n",
    "\n",
    "# 2. Load Raster Data (The Base DEM)\n",
    "# -----------------------------------------------------------------------------\n",
    "# We keep the source open or read immediately into memory. \n",
    "# Here we read the data and profile to establish the baseline grid/CRS.\n",
    "try:\n",
    "    with rasterio.open(files['dem']) as src:\n",
    "        dem = src.read(1)\n",
    "        base_profile = src.profile   # Metadata (CRS, Transform, Width, Height)\n",
    "        base_bounds = src.bounds     # Physical extent\n",
    "\n",
    "    with rasterio.open(files['gcm']) as src:\n",
    "        gcm = src.read(1)\n",
    "\n",
    "    print(\"dem and gcm loaded!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load DEM. {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d2a52-1a0d-4c01-977a-f9e9fd80965b",
   "metadata": {},
   "source": [
    "#### STEP A: De-stepping\n",
    "The Canonical DEM is quantified into 5 levels. We apply a wide-radius Gaussian Blur to the base elevation to turn these \"steps\" into continuous slopes, creating a smooth canvas for detailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ca0b06b-3c73-49db-ae68-f88ce19d2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from world_simulator import destep_terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c111281-50d9-4b3d-bb69-7bcbd07be842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "# Adjust radius based on your resolution. \n",
    "# If 1px ~= 125m, a 64px radius creates ~6km wide slopes.\n",
    "# Larger radius = smoother, wider ramps between the steps.\n",
    "BLUR_RADIUS = 64 \n",
    "ITERATIONS = 3\n",
    "SCALE_FACTOR = 2  # 1m = 2 units (so 50m = 100 units)\n",
    "\n",
    "OUTPUT_DIR = os.path.join(INPUT_DIR, \"source_rasters\")\n",
    "OUTPUT_FILENAME = \"phase2_a_destep.tif\"\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6023bbe6-acd8-4d4e-aab8-ade78b38e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nodata Value: -32768.0\n",
      "--- Starting Nodata-Aware De-stepping (R=64, I=3) ---\n",
      "  > Blur Pass 1/3...\n",
      "  > Blur Pass 2/3...\n",
      "  > Blur Pass 3/3...\n",
      "Restoring Nodata and quantizing...\n"
     ]
    }
   ],
   "source": [
    "# 2. Execution\n",
    "if 'dem' not in locals():\n",
    "    raise ValueError(\"Variable 'dem' not found. Load Phase 1 data first.\")\n",
    "\n",
    "# Extract Nodata value from the loaded profile\n",
    "# If not defined in file, default to -32768 (standard for int16)\n",
    "src_nodata = base_profile.get('nodata', None)\n",
    "if src_nodata is None:\n",
    "    src_nodata = -32768\n",
    "    print(f\"Warning: No Nodata in profile. Assuming {src_nodata}.\")\n",
    "else:\n",
    "    print(f\"Using Nodata Value: {src_nodata}\")\n",
    "\n",
    "# Run Nodata-Aware Smoothing\n",
    "smoothed_dem = destep_terrain(\n",
    "    dem_array=dem,\n",
    "    nodata_value=src_nodata,\n",
    "    radius=BLUR_RADIUS, \n",
    "    iterations=ITERATIONS, \n",
    "    scale_factor=SCALE_FACTOR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2fc939-1548-4715-8f67-90f5e2984455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to phase2_a_destep.tif...\n",
      "SUCCESS: De-stepping complete.\n",
      "  - Output shape: (10562, 16395)\n",
      "  - Min/Max values: -32768 / 32424\n",
      "  - Scale: 1 unit = 0.5 meters\n"
     ]
    }
   ],
   "source": [
    "# 3. Save to Compressed GeoTIFF\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"Saving result to {OUTPUT_FILENAME}...\")\n",
    "\n",
    "# Update metadata for the new format\n",
    "profile = base_profile.copy()\n",
    "profile.update({\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': rasterio.int16,\n",
    "    'count': 1,\n",
    "    'compress': 'lzw',\n",
    "    'predictor': 2,  # Horizontal differencing (good for elevation data)\n",
    "    'nodata': -32768 # Standard int16 nodata value\n",
    "})\n",
    "\n",
    "with rasterio.open(OUTPUT_PATH, 'w', **profile) as dst:\n",
    "    dst.write(smoothed_dem, 1)\n",
    "\n",
    "print(f\"SUCCESS: De-stepping complete.\")\n",
    "print(f\"  - Output shape: {smoothed_dem.shape}\")\n",
    "print(f\"  - Min/Max values: {np.min(smoothed_dem)} / {np.max(smoothed_dem)}\")\n",
    "print(f\"  - Scale: 1 unit = {1/SCALE_FACTOR} meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f9ff594-b561-44b2-a216-274d9bd5045e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Cleanup Memory\n",
    "# -----------------------------------------------------------------------------\n",
    "# We delete the smoothed array from RAM. \n",
    "# We keep 'dem' (original) and 'gcm' for the next prompt (Step B).\n",
    "del dem\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82675ca0-a230-4a2e-a899-f76713b5de69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13bf59-f052-48ab-8271-7a1284ad8a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e7fa8-6e86-419c-b574-dbb5e606e162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef543c1-eacd-4644-a924-c2fc6d355f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac3470-cdad-4b7b-b27d-ee2754603695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca5622-53bf-441f-a00b-96c066bf552b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ba1b8-0c88-42c5-a599-30975d0f2f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22140c-5702-4945-bc15-f163ff1ee047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c1f46a-f25a-4e85-847d-f2b189edc1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Warp Debug Grid...\n",
      "Check /home/pete/Documents/wfrp/debug_folding.tif in QGIS.\n",
      "If the grid lines are perfectly straight, the warp is BROKEN.\n",
      "If the grid lines curve near rivers, the warp WORKS.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  DEBUG: VISUALIZE THE WARP FIELD (Graph Paper Mode)\n",
    "# =============================================================================\n",
    "print(\"Generating Warp Debug Grid...\")\n",
    "\n",
    "# 1. Access the internal coordinate fabric\n",
    "# These should have been modified by the RiverWarpLayer\n",
    "warped_x = engine.coords_x\n",
    "warped_y = engine.coords_y\n",
    "\n",
    "# 2. Generate a Grid Pattern\n",
    "# We create white lines every 500 pixels\n",
    "spacing = 500      # Size of the grid squares (pixels)\n",
    "thickness = 40     # Thickness of the lines (pixels)\n",
    "\n",
    "# Logic: If the coordinate modulo spacing is less than thickness, draw a line.\n",
    "# This draws lines based on WHERE the pixel \"thinks\" it is in the warped space.\n",
    "vert_lines = (warped_x % spacing) < thickness\n",
    "horiz_lines = (warped_y % spacing) < thickness\n",
    "\n",
    "# Combine Vertical + Horizontal\n",
    "grid_pattern = np.logical_or(vert_lines, horiz_lines)\n",
    "\n",
    "# 3. Export\n",
    "debug_path = \"/home/pete/Documents/wfrp/debug_folding.tif\"\n",
    "with rasterio.open(debug_path, 'w', **base_profile) as dst:\n",
    "    # Convert Boolean (True/False) to Uint8 (255/0) for visibility\n",
    "    debug_img = grid_pattern.astype(np.uint8) * 255\n",
    "    dst.write(debug_img, 1)\n",
    "\n",
    "print(f\"Check {debug_path} in QGIS.\")\n",
    "print(\"If the grid lines are perfectly straight, the warp is BROKEN.\")\n",
    "print(\"If the grid lines curve near rivers, the warp WORKS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4259b-d4e2-4838-b192-b3a23d02b4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6547797-98fe-4770-ac90-67b4a8839dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0966ed36-1355-432c-b1ca-a5d592cc8481",
   "metadata": {},
   "source": [
    "What this will not do is getting a good coastal taper. For this we use the CoastalTaper class.\n",
    "For this we set ourselves at 250 pixels from the shore (which means base DEM elevation is reached some 27.25km from the Sea of Claws). The power is the default of 2 - this means a wide coastal plain and a steep rise that still preserves the hills in the north of Nordland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61542b5-7177-423a-9ba5-e5e5612a46f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cf7a3-017b-424c-af16-61b96978aca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c664d7a-eed1-44fa-8192-e307fc3c8b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bf085-4340-4cd8-b92a-08ea9daaf57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78069c-e899-49f5-a627-04b5dc32cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036b8bd-5402-4cfc-9099-8edf69491db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d1527-06b3-4064-afc9-fa07fac1c126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c3747-a930-48e3-8dac-ed62817ff5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56363c4-686d-42ed-9ac2-fd15bb57380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5e1eb-b2a6-426b-a722-ba01950104aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a080d-5d6e-4ec5-b20a-ade4e27c8330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d9a5f-96d5-4f27-acad-a34e4d69849d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(gdgtm_dev)",
   "language": "python",
   "name": "gdgtm_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
